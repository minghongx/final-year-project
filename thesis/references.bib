% https://bibtex.com/format/templates/
% https://tex.stackexchange.com/questions/516802/what-are-differences-amongst-conference-proceedings-and-inproceedings

@unpublished{ref:spec-report,
  author = {Minghong Xu},
  title  = {Final Year Project Specification Report},
  note   = {University of Liverpool},
  month  = 10,
  year   = 2022
}

@inproceedings{ref:virtual2real-drl,
  title        = {Virtual-to-real deep reinforcement learning: Continuous control of mobile robots for mapless navigation},
  author       = {Tai, Lei and Paolo, Giuseppe and Liu, Ming},
  booktitle    = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages        = {31--36},
  year         = 2017,
  organization = {IEEE},
  doi          = {10.1109/IROS.2017.8202134}
}

@inproceedings{ref:energy-efficient,
  author={Tang, Guangzhi and Kumar, Neelesh and Michmizos, Konstantinos P.},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Reinforcement co-Learning of Deep and Spiking Neural Networks for Energy-Efficient Mapless Navigation with Neuromorphic Hardware}, 
  year={2020},
  pages={6090-6097},
  doi={10.1109/IROS45743.2020.9340948}
}

@inproceedings{ref:huauv,
  author={Grando, Ricardo B. and de Jesus, Junior C. and Kich, Victor A. and Kolling, Alisson H. and Bortoluzzi, Nicolas P. and Pinheiro, Pedro M. and Neto, Armando A. and Drews, Paulo L. J.},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Deep Reinforcement Learning for Mapless Navigation of a Hybrid Aerial Underwater Vehicle with Medium Transition}, 
  year={2021},
  pages={1088-1094},
  doi={10.1109/ICRA48506.2021.9561188}
}

@book{ref:rl-intro,
  author = {Sutton, Richard S. and Barto, Andrew G.},
  edition = {Second},
  publisher = {The MIT Press},
  title = {Reinforcement Learning: An Introduction},
  url = {http://incompleteideas.net/book/the-book-2nd.html},
  year = 2018
}

@book{ref:neuro-dp,
  author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
  title = {Neuro-Dynamic Programming},
  year = {1996},
  isbn = {1886529108},
  publisher = {Athena Scientific},
  edition = {1st},
}

@article{ref:spinning-up,
  author = {Achiam, Joshua},
  title = {Spinning Up in Deep Reinforcement Learning},
  year = {2018}
}

@article{ref:q-learning,
  author={Watkins, Christopher J. C. H. and Dayan, Peter},
  title={Q-learning},
  journal={Machine Learning},
  year={1992},
  month={5},
  day={01},
  volume={8},
  number={3},
  pages={279-292},
  issn={1573-0565},
  doi={10.1007/BF00992698},
}

@inproceedings{ref:fn-approx,
  author = {Sutton, R. S. and Mcallester, D. and Singh, S. and Mansour, Y.},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  pages = {1057--1063},
  publisher = {MIT Press},
  title = {Policy gradient methods for reinforcement learning with function approximation},
  volume = 12,
  year = 2000
}

@article{ref:dqn,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  note = {NIPS Deep Learning Workshop 2013},
  title = {Playing Atari with Deep Reinforcement Learning},
  doi = {10.48550/arXiv.1312.5602},
  year = 2013
}

@article{ref:dqn-humanlevel,
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  issn = {00280836},
  journal = {Nature},
  month = 2,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group},
  title = {Human-level control through deep reinforcement learning},
  doi = {10.1038/nature14236},
  volume = 518,
  year = 2015
}

@inproceedings{ref:dpg,
  author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  title = {Deterministic Policy Gradient Algorithms},
  year = {2014},
  publisher = {JMLR.org},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML)},
  volume = {32},
  pages = {387--395},
  location = {Beijing, China},
  series = {ICML'14}
}

@inproceedings{ref:ddpg,
  title={Continuous Control with Deep Reinforcement Learning},
  author={Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle={International Conference on Learning Representations (ICLR)},
  editor = {Bengio, Yoshua and LeCun, Yann},
  doi = {10.48550/arXiv.1509.02971},
  year = 2016
}

@inproceedings{ref:td3,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author =       {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 2018,
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 80,
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {7},
  publisher =    {PMLR},
  doi = {10.48550/arXiv.1802.09477}
}

@inproceedings{ref:trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning (ICML)},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {7},
  publisher =    {PMLR},
  doi = {10.48550/arXiv.1502.05477},
}

@article{ref:ppo,
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {Computing Research Repository (CoRR)},
  title = {Proximal Policy Optimization Algorithms.},
  doi = {10.48550/arXiv.1707.06347},
  year = 2017
}

@inproceedings{ref:svg,
 author = {Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
 booktitle = {Advances in Neural Information Processing Systems (NIPS)},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 publisher = {Curran Associates, Inc.},
 title = {Learning Continuous Control Policies by Stochastic Value Gradients},
 doi = {10.48550/arXiv.1510.09142},
 volume = {28},
 year = {2015}
}

@inproceedings{ref:sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author =       {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning (ICML)},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  month = 	 {7},
  doi = {10.48550/arXiv.1801.01290},
}

@article{ref:sac-auto,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
  journal={Computing Research Repository (CoRR)},
  year={2018},
  doi = {10.48550/arXiv.1812.05905},
}

@article{ref:alphago,
author={Silver, David
and Huang, Aja
and Maddison, Chris J.
and Guez, Arthur
and Sifre, Laurent
and van den Driessche, George
and Schrittwieser, Julian
and Antonoglou, Ioannis
and Panneershelvam, Veda
and Lanctot, Marc
and Dieleman, Sander
and Grewe, Dominik
and Nham, John
and Kalchbrenner, Nal
and Sutskever, Ilya
and Lillicrap, Timothy
and Leach, Madeleine
and Kavukcuoglu, Koray
and Graepel, Thore
and Hassabis, Demis},
  title={Mastering the game of Go with deep neural networks and tree search},
  journal={Nature},
  year={2016},
  month={1},
  day={01},
  volume={529},
  number={7587},
  pages={484-489},
  issn={1476-4687},
  doi={10.1038/nature16961},
}

@article{ref:alphago-zero,
author={Silver, David
and Schrittwieser, Julian
and Simonyan, Karen
and Antonoglou, Ioannis
and Huang, Aja
and Guez, Arthur
and Hubert, Thomas
and Baker, Lucas
and Lai, Matthew
and Bolton, Adrian
and Chen, Yutian
and Lillicrap, Timothy
and Hui, Fan
and Sifre, Laurent
and van den Driessche, George
and Graepel, Thore
and Hassabis, Demis},
title={Mastering the game of Go without human knowledge},
  journal={Nature},
  year={2017},
  month={10},
  day={01},
  volume={550},
  number={7676},
  pages={354-359},
  issn={1476-4687},
  doi={10.1038/nature24270},
}

@article{ref:alphazero,
  author = {David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
  title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  journal = {Science},
  volume = {362},
  number = {6419},
  pages = {1140-1144},
  year = {2018},
  doi = {10.1126/science.aar6404},
}

@article{ref:muzero,
author={Schrittwieser, Julian
and Antonoglou, Ioannis
and Hubert, Thomas
and Simonyan, Karen
and Sifre, Laurent
and Schmitt, Simon
and Guez, Arthur
and Lockhart, Edward
and Hassabis, Demis
and Graepel, Thore
and Lillicrap, Timothy
and Silver, David},
  title={Mastering Atari, Go, chess and shogi by planning with a learned model},
  journal={Nature},
  year={2020},
  month={12},
  day={01},
  volume={588},
  number={7839},
  pages={604-609},
  issn={1476-4687},
  doi={10.1038/s41586-020-03051-4},
}

@misc{ref:drl-doesnt-work-yet,
  title={Deep Reinforcement Learning Doesn't Work Yet},
  author={Irpan, Alex},
  url={https://www.alexirpan.com/2018/02/14/rl-hard.html},
  urldate = {2023-04-04},
  day={14},
  month={2},
  year={2018},
}

@article{ref:drl-that-matters,
  title={Deep Reinforcement Learning That Matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  volume={32},
  doi={10.1609/aaai.v32i1.11694},
  number={1},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  year={2018},
  month={4}
}

@misc{ref:reproducing-drl,
  title={Lessons Learned Reproducing a Deep Reinforcement Learning Paper},
  author={Amid Fish},
  url={http://amid.fish/reproducing-deep-rl},
  urldate = {2023-04-04},
  day={06},
  month={4},
  year={2018},
}

@inproceedings{ref:sim2real,
  author={Zhao, Wenshuai and Queralta, Jorge Pe√±a and Westerlund, Tomi},
  booktitle={2020 IEEE Symposium Series on Computational Intelligence (SSCI)}, 
  title={Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey}, 
  year={2020},
  pages={737-744},
  doi={10.1109/SSCI47803.2020.9308468}
}

@article{ref:model-based-survey,
  year = {2023},
  volume = {16},
  journal = {Foundations and Trends in Machine Learning},
  title = {Model-based Reinforcement Learning: A Survey},
  doi = {10.1561/2200000086},
  issn = {1935-8237},
  number = {1},
  pages = {1-118},
  author = {Thomas M. Moerland and Joost Broekens and Aske Plaat and Catholijn M. Jonker}
}

@misc{ref:api,
  title={How to Maintain Clean Core APIs for Research},
  author={Yuxin Wu},
  url={https://ppwwyyxx.com/blog/2022/Maintain-Clean-Core-APIs-for-Research/},
  urldate = {2023-04-17},
  day={19},
  month={9},
  year={2022},
}

@techreport{ref:pep518,
  author  = {Brett Cannon and Nathaniel Smith and Donald Stufft},
  title   = {Specifying Minimum Build System Requirements for Python Projects},
  year    = {2016},
  type    = {PEP},
  number  = {518},
  url     = {https://peps.python.org/pep-0518/},
  urldate = {2022-11-10},
}
